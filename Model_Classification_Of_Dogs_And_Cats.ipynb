{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import joblib\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Download dataset\n",
        "url = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\"\n",
        "dataset_path = \"cats_and_dogs.zip\"\n",
        "\n",
        "if not os.path.exists(\"dataset\"):\n",
        "    print(\"Downloading dataset...\")\n",
        "    response = requests.get(url)\n",
        "    with open(dataset_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "\n",
        "    # Extract dataset\n",
        "    with ZipFile(dataset_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"dataset\")\n",
        "\n",
        "# Preprocess images\n",
        "def preprocess_image(image_path, size=(16, 16)):  # Reduced size for faster processing\n",
        "    try:\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image, size)\n",
        "        image = image / 255.0  # Normalize\n",
        "        return image\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def load_data(data_dir, label_map, subset_size=None):\n",
        "    images, labels = [], []\n",
        "    for label, folder in label_map.items():\n",
        "        folder_path = os.path.join(data_dir, folder)\n",
        "        for i, filename in enumerate(os.listdir(folder_path)):\n",
        "            if subset_size and i >= subset_size:\n",
        "                break\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            image = preprocess_image(file_path)\n",
        "            if image is not None:\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load data\n",
        "data_dir = \"dataset/PetImages\"\n",
        "label_map = {0: \"Cat\", 1: \"Dog\"}\n",
        "subset_size = 5000  # Use a subset for faster training\n",
        "images, labels = load_data(data_dir, label_map, subset_size=subset_size)\n",
        "\n",
        "# Flatten images for ML models (non-CNN models)\n",
        "flattened_images = images.reshape(len(images), -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "y_categorical = to_categorical(encoded_labels)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(flattened_images, encoded_labels, test_size=0.2, random_state=42)\n",
        "cnn_X_train, cnn_X_test, cnn_y_train, cnn_y_test = train_test_split(images, y_categorical, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train SVM\n",
        "print(\"Training SVM...\")\n",
        "svm_model = SVC(kernel='linear', C=0.1, probability=True)\n",
        "svm_model.fit(X_train, y_train)\n",
        "joblib.dump(svm_model, \"svm_model.pkl\")\n",
        "print(\"SVM training completed and saved.\")\n",
        "\n",
        "# Train Random Forest\n",
        "print(\"Training Random Forest...\")\n",
        "rf_model = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "joblib.dump(rf_model, \"rf_model.pkl\")\n",
        "print(\"Random Forest training completed and saved.\")\n"
      ],
      "metadata": {
        "id": "ToTKJFflYBIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8dfe5ee-f891-4ff5-9d8b-4cb035a4a9bc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n",
            "Training SVM...\n",
            "SVM training completed and saved.\n",
            "Training Random Forest...\n",
            "Random Forest training completed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train Logistic Regression (SGD)\n",
        "print(\"Training Logistic Regression...\")\n",
        "sgd_model = SGDClassifier(loss='log_loss', max_iter=1000, random_state=42)  # Updated loss parameter\n",
        "sgd_model.fit(X_train, y_train)\n",
        "joblib.dump(sgd_model, \"sgd_model.pkl\")\n",
        "print(\"Logistic Regression training completed and saved.\")\n",
        "\n",
        "\n",
        "# Train CNN\n",
        "print(\"Training CNN...\")\n",
        "cnn_model = Sequential([\n",
        "    Conv2D(16, (3, 3), activation='relu', input_shape=(16, 16, 3)),  # Fewer filters\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),  # Smaller dense layer\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "cnn_model.fit(cnn_X_train, cnn_y_train, epochs=30, batch_size=64, validation_data=(cnn_X_test, cnn_y_test))  # Fewer epochs\n",
        "cnn_model.save(\"cnn_model.h5\")\n",
        "print(\"CNN training completed and saved.\")\n",
        "\n",
        "# Load models for inference\n",
        "print(\"Loading models for inference...\")\n",
        "svm_model = joblib.load(\"svm_model.pkl\")\n",
        "rf_model = joblib.load(\"rf_model.pkl\")\n",
        "sgd_model = joblib.load(\"sgd_model.pkl\")\n",
        "cnn_model = load_model(\"cnn_model.h5\")\n",
        "\n",
        "# Test on one sample image\n",
        "sample_image = X_test[0].reshape(1, -1)  # For non-CNN models\n",
        "cnn_sample_image = cnn_X_test[0].reshape(1, 16, 16, 3)  # For CNN\n",
        "\n",
        "print(\"SVM Prediction:\", label_encoder.inverse_transform(svm_model.predict(sample_image)))\n",
        "print(\"Random Forest Prediction:\", label_encoder.inverse_transform(rf_model.predict(sample_image)))\n",
        "print(\"Logistic Regression Prediction:\", label_encoder.inverse_transform(sgd_model.predict(sample_image)))\n",
        "print(\"CNN Prediction:\", label_encoder.inverse_transform(np.argmax(cnn_model.predict(cnn_sample_image), axis=1)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDHlhJSQVVpd",
        "outputId": "4adaf74a-f3d5-457b-947f-25292386a776"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Logistic Regression...\n",
            "Logistic Regression training completed and saved.\n",
            "Training CNN...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.5320 - loss: 0.7045 - val_accuracy: 0.6399 - val_loss: 0.6513\n",
            "Epoch 2/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6337 - loss: 0.6429 - val_accuracy: 0.6660 - val_loss: 0.6026\n",
            "Epoch 3/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6800 - loss: 0.6008 - val_accuracy: 0.6710 - val_loss: 0.6013\n",
            "Epoch 4/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7016 - loss: 0.5779 - val_accuracy: 0.7166 - val_loss: 0.5694\n",
            "Epoch 5/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7114 - loss: 0.5676 - val_accuracy: 0.7121 - val_loss: 0.5632\n",
            "Epoch 6/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7211 - loss: 0.5586 - val_accuracy: 0.7232 - val_loss: 0.5483\n",
            "Epoch 7/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7419 - loss: 0.5341 - val_accuracy: 0.7146 - val_loss: 0.5546\n",
            "Epoch 8/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7334 - loss: 0.5330 - val_accuracy: 0.7272 - val_loss: 0.5418\n",
            "Epoch 9/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7531 - loss: 0.5114 - val_accuracy: 0.7161 - val_loss: 0.5565\n",
            "Epoch 10/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7692 - loss: 0.4898 - val_accuracy: 0.7382 - val_loss: 0.5273\n",
            "Epoch 11/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7738 - loss: 0.4844 - val_accuracy: 0.7322 - val_loss: 0.5327\n",
            "Epoch 12/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7775 - loss: 0.4664 - val_accuracy: 0.7397 - val_loss: 0.5304\n",
            "Epoch 13/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7725 - loss: 0.4694 - val_accuracy: 0.7417 - val_loss: 0.5349\n",
            "Epoch 14/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8043 - loss: 0.4360 - val_accuracy: 0.7332 - val_loss: 0.5307\n",
            "Epoch 15/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8068 - loss: 0.4271 - val_accuracy: 0.7322 - val_loss: 0.5389\n",
            "Epoch 16/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8189 - loss: 0.4089 - val_accuracy: 0.6901 - val_loss: 0.6094\n",
            "Epoch 17/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8272 - loss: 0.3936 - val_accuracy: 0.7322 - val_loss: 0.5452\n",
            "Epoch 18/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8497 - loss: 0.3572 - val_accuracy: 0.7347 - val_loss: 0.5547\n",
            "Epoch 19/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8482 - loss: 0.3602 - val_accuracy: 0.7302 - val_loss: 0.5565\n",
            "Epoch 20/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8550 - loss: 0.3424 - val_accuracy: 0.7352 - val_loss: 0.5971\n",
            "Epoch 21/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8590 - loss: 0.3279 - val_accuracy: 0.7332 - val_loss: 0.5797\n",
            "Epoch 22/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8832 - loss: 0.2977 - val_accuracy: 0.7317 - val_loss: 0.5811\n",
            "Epoch 23/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8863 - loss: 0.2852 - val_accuracy: 0.7307 - val_loss: 0.6467\n",
            "Epoch 24/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8850 - loss: 0.2823 - val_accuracy: 0.7222 - val_loss: 0.6233\n",
            "Epoch 25/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8978 - loss: 0.2561 - val_accuracy: 0.7282 - val_loss: 0.6223\n",
            "Epoch 26/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9095 - loss: 0.2420 - val_accuracy: 0.7302 - val_loss: 0.6430\n",
            "Epoch 27/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9188 - loss: 0.2229 - val_accuracy: 0.7242 - val_loss: 0.6611\n",
            "Epoch 28/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9273 - loss: 0.2115 - val_accuracy: 0.7262 - val_loss: 0.6587\n",
            "Epoch 29/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9302 - loss: 0.1991 - val_accuracy: 0.7202 - val_loss: 0.6917\n",
            "Epoch 30/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9383 - loss: 0.1860 - val_accuracy: 0.7272 - val_loss: 0.6999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN training completed and saved.\n",
            "Loading models for inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Prediction: [0]\n",
            "Random Forest Prediction: [1]\n",
            "Logistic Regression Prediction: [1]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n",
            "CNN Prediction: [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train K-Means\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # Suppress warnings for clean outpu\n",
        "print(\"Training K-Means...\")\n",
        "kmeans_model = KMeans(n_clusters=2, random_state=42)\n",
        "kmeans_model.fit(X_train)  # Unsupervised training on flattened images\n",
        "joblib.dump(kmeans_model, \"kmeans_model.pkl\")\n",
        "print(\"K-Means training completed and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf1GbkNgXMji",
        "outputId": "cac46d64-1a0f-47c3-fdfd-0f090a2caf03"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training K-Means...\n",
            "K-Means training completed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask-ngrok flask tensorflow scikit-learn pillow #1\n"
      ],
      "metadata": {
        "id": "1AZfqpheXMgD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35ed9fac-a787-4476-f73c-948ad0cbb6c3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jupyter-dash #2"
      ],
      "metadata": {
        "id": "1z1siVci_8_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6531a9f-a112-4f56-899b-8d934d850bc3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jupyter-dash\n",
            "  Downloading jupyter_dash-0.4.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting dash (from jupyter-dash)\n",
            "  Downloading dash-2.18.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from jupyter-dash) (2.32.3)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (from jupyter-dash) (3.1.0)\n",
            "Collecting retrying (from jupyter-dash)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from jupyter-dash) (7.34.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter-dash) (5.5.6)\n",
            "Collecting ansi2html (from jupyter-dash)\n",
            "  Downloading ansi2html-1.9.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from jupyter-dash) (1.6.0)\n",
            "Collecting flask (from jupyter-dash)\n",
            "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting Werkzeug<3.1 (from dash->jupyter-dash)\n",
            "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from dash->jupyter-dash) (5.24.1)\n",
            "Collecting dash-html-components==2.0.0 (from dash->jupyter-dash)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting dash-core-components==2.0.0 (from dash->jupyter-dash)\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting dash-table==5.0.0 (from dash->jupyter-dash)\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash->jupyter-dash) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from dash->jupyter-dash) (4.12.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from dash->jupyter-dash) (75.1.0)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask->jupyter-dash) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from flask->jupyter-dash) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask->jupyter-dash) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from flask->jupyter-dash) (1.9.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter-dash) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter-dash) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter-dash) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter-dash) (6.3.3)\n",
            "Collecting jedi>=0.16 (from ipython->jupyter-dash)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->jupyter-dash) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->jupyter-dash) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->jupyter-dash) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->jupyter-dash) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from retrying->jupyter-dash) (1.17.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->jupyter-dash) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask->jupyter-dash) (3.0.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->jupyter-dash) (0.7.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash->jupyter-dash) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash->jupyter-dash) (24.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyter-dash) (0.2.13)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash->jupyter-dash) (3.21.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (5.7.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.11/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (24.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->jupyter-dash) (4.3.6)\n",
            "Downloading jupyter_dash-0.4.2-py3-none-any.whl (23 kB)\n",
            "Downloading ansi2html-1.9.2-py3-none-any.whl (17 kB)\n",
            "Downloading dash-2.18.2-py3-none-any.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Downloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dash-table, dash-html-components, dash-core-components, Werkzeug, retrying, jedi, ansi2html, flask, dash, jupyter-dash\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: flask\n",
            "    Found existing installation: Flask 3.1.0\n",
            "    Uninstalling Flask-3.1.0:\n",
            "      Successfully uninstalled Flask-3.1.0\n",
            "Successfully installed Werkzeug-3.0.6 ansi2html-1.9.2 dash-2.18.2 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 flask-3.0.3 jedi-0.19.2 jupyter-dash-0.4.2 retrying-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "from jupyter_dash import JupyterDash   #3\n",
        "import dash_core_components as dcc\n",
        "import dash_html_components as html\n",
        "from dash.dependencies import Input, Output# Load Data"
      ],
      "metadata": {
        "id": "SwyGttzp2bE1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pyngrok  #4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDO2Ebz34FSL",
        "outputId": "b6be3e6f-5c8d-4946-d03e-2ad994cbae91"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask #5\n",
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "id": "HcBRzWjm4dDu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.set_auth_token('2rt5L03UtaVeBd6H3jtAL03eB5A_83J2h8Fb7z8kFxL4cmkWx')\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "print(public_url) #6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5JWMOJ5AWjM",
        "outputId": "16a02a7f-46c9-4c92-915e-c0bf22a8307d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://2874-34-125-31-114.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create templates directory\n",
        "os.makedirs(\"templates\", exist_ok=True)\n",
        "\n",
        "# Create result.html file inside templates directory\n",
        "html_content = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Prediction Result</title>\n",
        "    <style>\n",
        "        body {\n",
        "            font-family: Arial, sans-serif;\n",
        "            background-color: #f4f4f9;\n",
        "            display: flex;\n",
        "            justify-content: center;\n",
        "            align-items: center;\n",
        "            height: 100vh;\n",
        "            margin: 0;\n",
        "        }\n",
        "        .container {\n",
        "            text-align: center;\n",
        "            background: #ffffff;\n",
        "            padding: 20px;\n",
        "            border-radius: 10px;\n",
        "            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
        "            width: 400px;\n",
        "        }\n",
        "        h1 {\n",
        "            color: #333;\n",
        "        }\n",
        "        p {\n",
        "            font-size: 16px;\n",
        "            color: #555;\n",
        "        }\n",
        "        a {\n",
        "            text-decoration: none;\n",
        "            color: #4CAF50;\n",
        "            font-weight: bold;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <h1>Prediction Result</h1>\n",
        "        <p>Model Used: {{ model }}</p>\n",
        "        <p>Prediction: {{ prediction }}</p>\n",
        "        <a href=\"/\">Go back</a>\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# Write the HTML content to result.html\n",
        "with open(\"templates/result.html\", \"w\") as file:\n",
        "    file.write(html_content)\n"
      ],
      "metadata": {
        "id": "DZYQdYICiA2U"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify, render_template\n",
        "import joblib\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Set up ngrok\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n",
        "# Load models\n",
        "svm_model = joblib.load(\"svm_model.pkl\")\n",
        "rf_model = joblib.load(\"rf_model.pkl\")\n",
        "sgd_model = joblib.load(\"sgd_model.pkl\")\n",
        "cnn_model = load_model(\"cnn_model.h5\")\n",
        "kmeans_model = joblib.load(\"kmeans_model.pkl\")  # Load KMeans model\n",
        "\n",
        "# Label map\n",
        "label_map = {0: \"Cat\", 1: \"Dog\"}\n",
        "\n",
        "def inverse_label(label_idx):\n",
        "    return label_map[label_idx]\n",
        "\n",
        "# Preprocess image\n",
        "def preprocess_image(image_file, size=(16, 16)):\n",
        "    image = cv2.imdecode(np.frombuffer(image_file.read(), np.uint8), cv2.IMREAD_COLOR)\n",
        "    if image is None:\n",
        "        return None\n",
        "    image = cv2.resize(image, size)\n",
        "    image = image / 255.0  # Normalize\n",
        "    return image\n",
        "\n",
        "# Root route\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"\"\"\n",
        "    <html>\n",
        "        <head>\n",
        "            <title>Cat and Dog Classifier</title>\n",
        "            <style>\n",
        "                body {\n",
        "                    font-family: Arial, sans-serif;\n",
        "                    background-color: #f4f4f9;\n",
        "                    margin: 0;\n",
        "                    padding: 0;\n",
        "                    display: flex;\n",
        "                    justify-content: center;\n",
        "                    align-items: center;\n",
        "                    height: 100vh;\n",
        "                }\n",
        "                .container {\n",
        "                    text-align: center;\n",
        "                    background: #ffffff;\n",
        "                    padding: 20px;\n",
        "                    border-radius: 10px;\n",
        "                    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
        "                    width: 400px;\n",
        "                }\n",
        "                h1 {\n",
        "                    color: #333;\n",
        "                }\n",
        "                label {\n",
        "                    font-size: 16px;\n",
        "                    color: #555;\n",
        "                }\n",
        "                input[type=\"file\"], select {\n",
        "                    margin-top: 10px;\n",
        "                    margin-bottom: 20px;\n",
        "                }\n",
        "                button {\n",
        "                    background-color: #4CAF50;\n",
        "                    color: white;\n",
        "                    border: none;\n",
        "                    padding: 10px 20px;\n",
        "                    text-align: center;\n",
        "                    font-size: 16px;\n",
        "                    border-radius: 5px;\n",
        "                    cursor: pointer;\n",
        "                    transition: background-color 0.3s;\n",
        "                }\n",
        "                button:hover {\n",
        "                    background-color: #45a049;\n",
        "                }\n",
        "            </style>\n",
        "        </head>\n",
        "        <body>\n",
        "            <div class=\"container\">\n",
        "                <h1>Cat and Dog Classifier</h1>\n",
        "                <form action=\"/predict\" method=\"post\" enctype=\"multipart/form-data\">\n",
        "                    <label for=\"image\">Upload an image:</label><br>\n",
        "                    <input type=\"file\" name=\"image\" accept=\"image/*\" required><br>\n",
        "                    <label for=\"model\">Choose a model:</label><br>\n",
        "                    <select name=\"model\" required>\n",
        "                        <option value=\"svm\">SVM</option>\n",
        "                        <option value=\"rf\">Random Forest</option>\n",
        "                        <option value=\"sgd\">SGD</option>\n",
        "                        <option value=\"cnn\">CNN</option>\n",
        "                        <option value=\"kmeans\">KMeans</option>\n",
        "                    </select><br>\n",
        "                    <button type=\"submit\">Predict</button>\n",
        "                </form>\n",
        "            </div>\n",
        "        </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "# Prediction route\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    if 'image' not in request.files:\n",
        "        return jsonify({'error': 'No image uploaded'}), 400\n",
        "\n",
        "    if 'model' not in request.form:\n",
        "        return jsonify({'error': 'No model selected'}), 400\n",
        "\n",
        "    image_file = request.files['image']\n",
        "    selected_model = request.form['model']\n",
        "    image = preprocess_image(image_file)\n",
        "\n",
        "    if image is None:\n",
        "        return jsonify({'error': 'Invalid image format'}), 400\n",
        "\n",
        "    # Flatten image for non-CNN models\n",
        "    flattened_image = image.reshape(1, -1)\n",
        "\n",
        "    # CNN requires a 4D tensor\n",
        "    cnn_image = image.reshape(1, 16, 16, 3)\n",
        "\n",
        "    # Make prediction based on selected model\n",
        "    if selected_model == \"svm\":\n",
        "        prediction = inverse_label(svm_model.predict(flattened_image)[0])\n",
        "    elif selected_model == \"rf\":\n",
        "        prediction = inverse_label(rf_model.predict(flattened_image)[0])\n",
        "    elif selected_model == \"sgd\":\n",
        "        prediction = inverse_label(sgd_model.predict(flattened_image)[0])\n",
        "    elif selected_model == \"cnn\":\n",
        "        prediction = inverse_label(np.argmax(cnn_model.predict(cnn_image), axis=1)[0])\n",
        "    elif selected_model == \"kmeans\":\n",
        "        cluster = kmeans_model.predict(flattened_image)[0]\n",
        "        prediction = f\"Cluster {cluster}\"\n",
        "    else:\n",
        "        return jsonify({'error': 'Invalid model selected'}), 400\n",
        "\n",
        "    return render_template('result.html', model=selected_model, prediction=prediction)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(port=5000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBuVHpFXia2Q",
        "outputId": "db27eb68-f839-43e8-9393-1a18a35eb9d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://733f-34-125-31-114.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Jan/2025 17:18:11] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Jan/2025 17:18:12] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Jan/2025 17:18:57] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Jan/2025 17:19:02] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Jan/2025 17:30:22] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Jan/2025 17:31:16] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Jan/2025 17:37:35] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Jan/2025 17:53:42] \"GET / HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0: \"Cat\", 1: \"Dog\"\n"
      ],
      "metadata": {
        "id": "nZdB9UhMxBhX"
      }
    }
  ]
}